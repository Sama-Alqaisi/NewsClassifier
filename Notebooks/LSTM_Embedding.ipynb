{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BWHcyi_wKHKF",
        "bTlxp4p5KMj9",
        "1y6YLML_KPxo",
        "XKgsDnNcKWXC",
        "KU8NxMJbubLa",
        "XFhLg3LSU62P",
        "XxWR3qROVXMu",
        "NCG9JgvPVbiw",
        "SJx9T2Elb7tA",
        "DJAooC6La3IL",
        "BsNsZ8dQg5q5",
        "Gor3-2Eig9zP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEwKgHcnQG1E",
        "outputId": "02817ea9-7562-4df0-fe89-837e16d5178a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWHcyi_wKHKF"
      },
      "source": [
        "# **Read Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Ddi51CWox8CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpZCgTzMAiw8"
      },
      "outputs": [],
      "source": [
        "news_train=pd.read_excel('/content/drive/MyDrive/News_train.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSchvg9YQ-QE",
        "outputId": "17e152d8-7579-4ef1-a6f1-a1ea9fecefbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_test=pd.read_excel('/content/drive/MyDrive/News_test.xlsx')"
      ],
      "metadata": {
        "id": "V7oq3a0LxjGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfaQKTlcxk0N",
        "outputId": "55bf449e-7798-4d30-9a00-fed7bb6e9510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTlxp4p5KMj9"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y6YLML_KPxo"
      },
      "source": [
        "### **re**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llK2Eci2AyS1",
        "outputId": "7428408c-7929-4268-9a0b-a8e88a43a1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import unicodedata\n",
        "from nltk import word_tokenize\n",
        "from nltk import download\n",
        "\n",
        "nltk.download('punkt')\n",
        "download('stopwords')\n",
        "\n",
        "def normalize_arabic(text):\n",
        "    words = text.split()\n",
        "\n",
        "    # Normalize Arabic text\n",
        "    text = ' '.join(words)\n",
        "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn') # remove diacritics\n",
        "    text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"ء\", text)\n",
        "    text = re.sub(\"ئ\", \"ء\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub('/', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    text = re.sub('_', ' ', text)\n",
        "    text = re.sub(' و ', ' ', text)\n",
        "    text = re.sub(\"'\", ' ', text)\n",
        "    text = re.sub(\"``\", ' ', text)\n",
        "    text = re.sub('\"', ' ', text)\n",
        "    text = re.sub('%', ' ', text)\n",
        "    text = re.sub('»', ' ', text)\n",
        "    text = re.sub('«', ' ', text)\n",
        "    text = re.sub(r'\\bال(\\w+)\\b', r'\\1', text)\n",
        "    text = re.sub(r'\\bلل(\\w+)\\b', r'\\1', text)\n",
        "    text = re.sub(r'\\bبال(\\w+)\\b', r'\\1', text)\n",
        "    text = re.sub(r'[A-Za-z0-9]', r'', text)#remove english characters\n",
        "    text = re.sub(r'[0-9]', r'', text)#remove numbers\n",
        "    text = re.sub(r'[^\\w\\s]', r'', text)#remove punctuation\n",
        "\n",
        "    #text = re.sub(r'\\bوال(\\w+)\\b', r'\\1', text)\n",
        "\n",
        "    words = word_tokenize(text)\n",
        "    normalized_text = ' '.join(words)\n",
        "\n",
        "    return normalized_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHJtqAx-C65d"
      },
      "outputs": [],
      "source": [
        "news_train['News'] = news_train['News'].apply(normalize_arabic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNnNttwgC62o",
        "outputId": "c2200351-9a6b-43d3-f6db-f0b44df739f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       اشتباك حريري عون اتهامات لباسيل تمسك ثلث معطل ...\n",
              "1                               عون حريري اصبح غريب اطوار\n",
              "2       وزير خارجيه امريكي ندرس سحب كامل قواتنا من افغ...\n",
              "3       افغانستان استعدادات حثيثه لاجتماع تركيا وكابل ...\n",
              "4                   اندبندنت مفاوضات سريه كادت تنقذ قذافي\n",
              "                              ...                        \n",
              "4995                اوروبا تبدا احصاء خساير فيضانات مدمره\n",
              "4996    قتل متظاهر رصاص خلال احتجاجات علي شح مياه في م...\n",
              "4997    وسايل اعلام ايرانيه تتحدث عن اندلاع احتجاجات ف...\n",
              "4998           مفاوضات افغانيه تتواصل في عاصمه قطريه دوحه\n",
              "4999    تعليق مفاوضات افغانيه في دوحه موقتا لمزيد من م...\n",
              "Name: News, Length: 5000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "news_train['News']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiSx6tOrhv3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "824d4ff1-57d0-4343-85e3-350ec12d456e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "news_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_test['News'] = news_test['News'].apply(normalize_arabic)"
      ],
      "metadata": {
        "id": "YOxXPZaUyTvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_test['News']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nrxTrneyWiW",
        "outputId": "56620387-9c33-4c1c-a1e1-fc176079204a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                            ميات قتلي في فيضانات اوروبا\n",
              "1        جوله مفاوضات جديده تفشل في كسر جمود ازمه قبرصيه\n",
              "2      قضاء فرنسي يفتح تحقيقا حول بيغاسوس بشان تجسس ع...\n",
              "3        وزير دفاع اسراييلي يزور فرنسا لبحث قضيه بيغاسوس\n",
              "4      بدا في عده دول سريان حظر شامل حد من انتشار فير...\n",
              "                             ...                        \n",
              "995    هواوي عقوبات اميركيه علي شركه مسووله جزييا عن ...\n",
              "996          مجهر من هواتف محموله قديمه مدارس في تايلاند\n",
              "997             هواتف ذكيه شبيهه ليجو تشق طريقها ي اسواق\n",
              "998    بعد هواوي واشنطن تضيف شركه شياومي صينيه ي قايم...\n",
              "999                      شياومي خارج قايمه سوداء اميركيه\n",
              "Name: News, Length: 1000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8Cu4tcyyduZ",
        "outputId": "1a8f5fc6-1159-407b-9649-2f4f776960c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKgsDnNcKWXC"
      },
      "source": [
        "### **nltk**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HG-0qBlFixO"
      },
      "outputs": [],
      "source": [
        "# Text Mining\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer('arabic')\n",
        "\n",
        "\n",
        "# Your list of Arabic stop words\n",
        "additional_arabic_stopwords = [\"تم\", 'اي', 'لكن', 'أو', 'في', 'و','بدون', 'من', 'علي', 'إلي', 'التي']\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenization for Arabic text using NLTK word_tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Add additional Arabic stop words here\n",
        "    stop_words_arabic = set(stopwords.words('arabic') + additional_arabic_stopwords)\n",
        "    arabic_tokens = [token for token in tokens if token not in stop_words_arabic]\n",
        "\n",
        "    # stemming in Arabic text\n",
        "    arabic_tokens = [stemmer.stem(token) for token in arabic_tokens]\n",
        "\n",
        "    # Remove punctuation for Arabic text\n",
        "    arabic_tokens = [token for token in arabic_tokens if re.match(r'\\w', token)]\n",
        "\n",
        "    # Join tokens back into text\n",
        "    processed_text = ' '.join(arabic_tokens)\n",
        "\n",
        "    return processed_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eIzGzoYZ9HO"
      },
      "outputs": [],
      "source": [
        "preprocessed_documents_news_train = [preprocess_text(doc) for doc in news_train['News']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfRwf66caP9A",
        "outputId": "ffc86146-cda0-426d-c2f0-b26e457da89a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(preprocessed_documents_news_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_documents_news_test = [preprocess_text(doc) for doc in news_test['News']]"
      ],
      "metadata": {
        "id": "9vmazvfLyyGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(preprocessed_documents_news_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txk9m-8byz72",
        "outputId": "ee6bafbb-82af-462e-d012-5af62c340e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU8NxMJbubLa"
      },
      "source": [
        "# **Splitting the data into training and validation**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_train['processed_text'] = preprocessed_documents_news_train"
      ],
      "metadata": {
        "id": "bmuPmwOHqSfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_train['processed_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRtdxYItZm5K",
        "outputId": "b07cfc15-9f53-4bd2-e8e5-8f2b4dd483f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          اشتب حرير عون اتهام باسيل تمس ثلث معطل قاء حكم\n",
              "1                                عون حرير اصبح غريب اطوار\n",
              "2             زير خارج امر ندرس سحب كامل قوا افغانست حلول\n",
              "3       افغانست استعداد حثيث اجتماع ترك كابل تتهم طالب...\n",
              "4                          اندبندن مفاوض سر كاد تنقذ قذاف\n",
              "                              ...                        \n",
              "4995                      اوروب تبد احصاء خساير يضان مدمر\n",
              "4996    قتل متظاهر رصاص خلال احتجاج شح ميا منطق جنوب غ...\n",
              "4997           سايل اعلام ايران تتحدث اندلاع احتجاج شوارع\n",
              "4998                      مفاوض افغان تتواصل عاصم قطر دوح\n",
              "4999                 تعليق مفاوض افغان دوح موق مزيد مشاور\n",
              "Name: processed_text, Length: 5000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUTqRljYZB_e",
        "outputId": "aa9e96a5-5439-414a-8f60-508fac8a5eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Type', 'News', 'processed_text'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=news_train['Type']\n",
        "X=news_train.drop(columns=['Type', 'News'], axis=1)"
      ],
      "metadata": {
        "id": "J7VAT3txjvER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
      ],
      "metadata": {
        "id": "sfwoItxEjelq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oUkNNUOb1fL",
        "outputId": "ce44364f-6f71-4a88-b03e-4ceb4358a15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4250"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFhLg3LSU62P"
      },
      "source": [
        "# **Word Embedding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxWR3qROVXMu"
      },
      "source": [
        "### **TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66aXlyvdVDId"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=300)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train['processed_text'])\n",
        "X_test_tfidf = vectorizer.fit_transform(X_test['processed_text'])\n",
        "\n",
        "\n",
        "tfidf_train_feature = pd.DataFrame(X_train_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "tfidf_test_feature = pd.DataFrame(X_test_tfidf.toarray(), columns=vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tfidf_train_feature.columns:\n",
        "    embedding = tfidf_train_feature[word].values\n",
        "    print(\"Word:\", word, \", vector:\", embedding)\n",
        "#print(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-ra82NZJch",
        "outputId": "76103404-78d4-465f-de44-58a743546a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: ابطال , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اتحاد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اتفاق , vector: [0.         0.         0.         ... 0.         0.38085582 0.        ]\n",
            "Word: اتهام , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اثيوب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اجتماع , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اجنب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: احتجاج , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: احتلال , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: احد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اخر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ادار , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اراض , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ارتفاع , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ارد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اردن , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اريس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ازم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: استثمار , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اسراييل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اسعار , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اسلام , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اصاب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اطلاق , vector: [0.         0.29513072 0.         ... 0.         0.27953386 0.        ]\n",
            "Word: اعل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اعلن , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: افريق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: افغانست , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اقتصاد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اقص , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اقليم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اكثر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اكست , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: امار , vector: [0.        0.        0.5128076 ... 0.        0.        0.       ]\n",
            "Word: امام , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: امر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: امم , vector: [0.         0.         0.         ... 0.70545957 0.         0.        ]\n",
            "Word: امن , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: امير , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ان , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: انتخاب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: انخفاض , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: انسحاب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: انقلاب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: انه , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اوروب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اول , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ايد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: اير , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ايرا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ايران , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ايطال , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: بحر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: بدا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: بشا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: بنان , vector: [0.55201049 0.         0.         ... 0.         0.         0.        ]\n",
            "Word: بنك , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تاريخ , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تجار , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تحقيق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تراجع , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ترفض , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ترك , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تشاد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تشكيل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تطالب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تطلق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تطور , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تعاو , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تعرض , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تعزيز , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تعل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تهد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تواصل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: توتنهام , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: تونس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: جايح , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: جديد , vector: [0.         0.         0.         ... 0.         0.         0.40233382]\n",
            "Word: جرايم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: جرح , vector: [0.         0.         0.         ... 0.         0.49398835 0.        ]\n",
            "Word: جماهير , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: جمع , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: جنوب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: جو , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: جول , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: جيرم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: جيش , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حاشد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حال , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حجم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حدود , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حرب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حرك , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حره , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حريق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حزب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حكوم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حماس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حوث , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: حول , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: خارج , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: خروج , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: خساير , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: خطه , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: خلاف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: خلال , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: داخل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: دخول , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: دعو , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: دفاع , vector: [0.         0.         0.         ... 0.         0.37713382 0.        ]\n",
            "Word: دور , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: دول , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: رازيل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ربع , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: رسم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: رشل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: رغم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: رفع , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: رقم , vector: [0.         0.         0.         ... 0.70875016 0.         0.        ]\n",
            "Word: رنس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: روس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: رياس , vector: [0.         0.         0.         ... 0.         0.46760003 0.        ]\n",
            "Word: رياض , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ريطان , vector: [0.         0.35435115 0.         ... 0.         0.         0.        ]\n",
            "Word: ريق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: رييس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: زار , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: زراء , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: زير , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سابق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سان , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سبب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سطين , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سعود , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سقوط , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سلام , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سلط , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سوبر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سود , vector: [0.         0.         0.         ... 0.         0.         0.57894804]\n",
            "Word: سودا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سور , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سوق , vector: [0.         0.         0.         ... 0.         0.41461485 0.        ]\n",
            "Word: سيار , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: سياس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: شخص , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: شرط , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: شرق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: شرك , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: شمال , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: شهر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: شيخ , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: صاروخ , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: صح , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: صحه , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: صحيف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: صناع , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: صواريخ , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: صين , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ضخم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ضد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ضفه , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: طالب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: طاير , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: طريق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: طلب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: طول , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: طيرا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عالم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عام , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عدد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عدوا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عراق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عرب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عسكر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عشر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عقب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عقد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عقود , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: علاق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: عمل , vector: [0.         0.         0.55776248 ... 0.         0.         0.        ]\n",
            "Word: عود , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: غار , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: غاز , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: غرب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: غزه , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: غضب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: فوز , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: في , vector: [0.         0.46017627 0.         ... 0.         0.         0.48355368]\n",
            "Word: فيروس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قال , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قاهر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قايم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قتال , vector: [0.        0.5215509 0.        ... 0.        0.        0.       ]\n",
            "Word: قتل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قدس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قدم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قصف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قض , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قطاع , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قطر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قلق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: قوا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: كاس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: كال , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: كبير , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: كره , vector: [0.         0.         0.         ... 0.         0.         0.51877018]\n",
            "Word: كشف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: كور , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: لاد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: لاعب , vector: [0.         0.         0.41595819 ... 0.         0.         0.        ]\n",
            "Word: لاول , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: لبحث , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: لبنا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: لحل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: لسط , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: لقاء , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: لقاح , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ليب , vector: [0.37365827 0.         0.         ... 0.         0.         0.        ]\n",
            "Word: لير , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مال , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مان , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مبار , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مبعوث , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: متحد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مثير , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مجلس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: محتل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: محكم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: محل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مخاوف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مدريد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مدن , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مركز , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مره , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مساعد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مستشف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مستقبل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مستوطن , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مسجد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مسوول , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مسير , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مشتر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مشروع , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مصالح , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مصر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مظاهر , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مفاوض , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مقاوم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مقتل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ملا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ملك , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مليار , vector: [0.         0.55095878 0.         ... 0.         0.         0.        ]\n",
            "Word: مليو , vector: [0.         0.         0.50289976 ... 0.         0.         0.        ]\n",
            "Word: منتخب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: منتد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: منطق , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: منظم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: مواج , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: موج , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ميا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ميانمار , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ميس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ناد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: نار , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: نتن , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: نجم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: نسب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: نظام , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: نفط , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: نها , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: نهض , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: نواب , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: نوو , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: هجم , vector: [0.53695131 0.         0.         ... 0.         0.         0.        ]\n",
            "Word: هجوم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: هدف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: هدن , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: هرباء , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: هند , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: واشنط , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: وحد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: وسط , vector: [0.51705628 0.         0.         ... 0.         0.         0.        ]\n",
            "Word: وطن , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: وف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: وفد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: وقف , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: ولا , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: يبحث , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: يدع , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: يروس , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: يعل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: يمن , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: يواصل , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: يوكد , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: يوم , vector: [0. 0. 0. ... 0. 0. 0.]\n",
            "Word: يويف , vector: [0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCG9JgvPVbiw"
      },
      "source": [
        "### **Bag Of Words**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = cv_uni_vec = CountVectorizer(max_features=300,\n",
        "                                 stop_words=None,\n",
        "                                 ngram_range=(2,2))\n",
        "X_train_uni = cv_uni_vec.fit_transform(X_train['processed_text'])\n",
        "X_test_uni = cv_uni_vec.fit_transform(X_test['processed_text'])\n",
        "\n",
        "BOW_train_feature = pd.DataFrame(X_train_uni.toarray(), columns=cv_uni_vec.get_feature_names_out())\n",
        "BOW_test_feature = pd.DataFrame(X_test_uni.toarray(), columns=cv_uni_vec.get_feature_names_out())"
      ],
      "metadata": {
        "id": "e-fHbMc1a0Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in BOW_train_feature.columns:\n",
        "  embedding = BOW_train_feature[word].values\n",
        "  print(\"Word:\", word, \", vector:\", embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRTe2BZEZeGZ",
        "outputId": "fc2548c3-6bc0-4243-967e-4eaf9b604ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: ابطال افريق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ابطال اوروب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اتحاد اوروب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اتحاد طيرا , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اتفاق تجار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اتفاق سلام , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اتفاق نوو , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اثناء مبار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: احتلال اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: احتلال نفذ , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اداء امر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ادار ايد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ادريس ديب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ادن اجور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ارتفاع اسعار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اريس سان , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ازم سد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ازم كور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: استشهاد سطين , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اسراييل سطين , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اسراييل غزه , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اسراييل فلسطين , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اسراييل نتن , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اسعار نفط , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اصاب جديد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اصاب فيروس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اصاب كور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اصو انتخاب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اطلاق نار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اعاد اعمار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اعتداء اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اعلام اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اعلن زار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اعمار غزه , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اعمال بنان , vector: [0 0 0 ... 0 0 0]\n",
            "Word: افغانست طالب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اقتصاد ريط , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اقتصاد عالم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اقليم ردست , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اكثر غار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اكد رييس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: امام مقر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: امر تعل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: امر مان , vector: [0 0 0 ... 0 0 0]\n",
            "Word: امم اوروب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: امم متحد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: امن دول , vector: [0 0 0 ... 0 0 0]\n",
            "Word: امير قطر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: امير يبحث , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انباء عالم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انتخاب اقليم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انتخاب تشريع , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انتخاب رلمان , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انتخاب رياس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انتر ميلا , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انتصار مقاوم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انخفاض اسعار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اندلاع حريق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انسحاب افغانست , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انسحاب قوا , vector: [0 0 0 ... 0 0 0]\n",
            "Word: انقلاب ميانمار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اولمب دول , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ايد تطالب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ايد يتعهد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: اير ميونخ , vector: [0 0 0 ... 0 0 0]\n",
            "Word: باح مسجد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: بحر امير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: بشا سد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: بقو درج , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تايب قسام , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تبادل تجار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تجار حره , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تجار عالم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تجار كترونيه , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تحطم طاير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تخرج طول , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تخصيب يورانيوم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تراجع سعر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تراجع كبير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ترك سور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تسجيل اكثر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تشكيل حكوم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تشكيل لجن , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تصريف اعمال , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تصريف امطار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تطالب وقف , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تطور مفاوض , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تعاط ماريج , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تعاو دول , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تعاو مشتر , vector: [0 0 0 ... 0 1 0]\n",
            "Word: تعزيز علاق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تعل بدء , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تعل سيطر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تنديد عدوا , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تهد غزه , vector: [0 0 0 ... 0 0 0]\n",
            "Word: تهم قتل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: توصل اتفاق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: توقيع اتفاق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ثقه حكوم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: جايح كور , vector: [0 0 0 ... 0 0 1]\n",
            "Word: جديد كور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: جديد مصر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: جرايم حرب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: جرع لقاح , vector: [0 0 0 ... 0 0 0]\n",
            "Word: جنا دول , vector: [0 0 0 ... 0 0 0]\n",
            "Word: جو ايد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: جيش احتلال , vector: [0 0 0 ... 0 0 0]\n",
            "Word: جيش اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حاشد امام , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حجر صح , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حجم استثمار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حد ادن , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حرب امر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حرب عالم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حصيل وف , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حكوم بنان , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حكوم تصريف , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حكوم وحد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حكوم يمن , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حوث صنعاء , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حول سد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: حي شيخ , vector: [0 0 0 ... 0 0 0]\n",
            "Word: خارج رنس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: خارج ملعب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: خساير يضان , vector: [0 0 0 ... 0 0 0]\n",
            "Word: خليل زاد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: داخل غزه , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دفاع امر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دفاع امير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دفاع مصالح , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دور ابطال , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دور اسب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دور اوروب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دور ايطال , vector: [0 0 0 ... 0 1 0]\n",
            "Word: دور سوبر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دور مان , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دول اوروب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دول عقد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: دينام زغرب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: رايتس وتش , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ربع نها , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ردست عراق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: رغم دعو , vector: [0 1 0 ... 0 0 0]\n",
            "Word: رقم قياس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: رياس عراق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: رييس اكست , vector: [0 0 0 ... 0 0 0]\n",
            "Word: رييس امر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: رييس امير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: رييس تونس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: رييس حكوم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: رييس دول , vector: [0 0 0 ... 0 0 0]\n",
            "Word: رييس زراء , vector: [0 0 0 ... 0 0 0]\n",
            "Word: زار دفاع , vector: [0 0 0 ... 0 0 0]\n",
            "Word: زار صحه , vector: [0 0 0 ... 0 0 0]\n",
            "Word: زراء ليب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: زلزال بقو , vector: [0 0 0 ... 0 0 0]\n",
            "Word: زير خارج , vector: [0 0 0 ... 0 0 0]\n",
            "Word: زير داخل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: زير دفاع , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سان جيرم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سان طرسبورغ , vector: [0 0 0 ... 0 1 0]\n",
            "Word: سبب ارتفاع , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سبب اصاب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سبب كور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سد نهض , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سعود امار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سعود يبحث , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سف اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سفار قدس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سلام اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سلط سطين , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سله امير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: سوبر اوروب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: شرط جديد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: شرق اوسط , vector: [0 0 0 ... 0 0 0]\n",
            "Word: شكل كامل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: شيخ جراح , vector: [0 0 0 ... 0 0 0]\n",
            "Word: شيوخ امر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: صايل سطين , vector: [0 0 0 ... 0 0 0]\n",
            "Word: صح هند , vector: [0 0 0 ... 0 0 0]\n",
            "Word: صحه عالم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: صحيف اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: صحيف امير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: صندوق نقد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ضفه غرب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: طالب تعل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: طاير عسكر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: طاير مسير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: طلب نفط , vector: [0 0 0 ... 0 0 0]\n",
            "Word: طول عالم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: طيار اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عاصم قطر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عالم ثان , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عدوا اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عشر جرح , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عشر ضحا , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عشر قتل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عقد جلس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عمل سلام , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عمل عسكر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عنيف قطاع , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عهد سعود , vector: [0 0 0 ... 0 0 0]\n",
            "Word: عود اتفاق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: غار اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: غاريث بيل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: غرب قدس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: غزه احتلال , vector: [0 0 0 ... 0 0 0]\n",
            "Word: فتح طريق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: فوز مثير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: فيروس كور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قال صحيف , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قايد جيش , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قدس محتل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قرار تشكيل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قطاع غزه , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قطر دوح , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قطر يبحث , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قمه حول , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قنا سويس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قوا اجنب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قوا احتلال , vector: [0 0 0 ... 0 0 0]\n",
            "Word: قوا امير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: كال انباء , vector: [0 0 0 ... 0 0 0]\n",
            "Word: كره قدم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: كوب امير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: كور جنوب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: كور شمال , vector: [0 0 0 ... 0 0 0]\n",
            "Word: كور ممل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لاعب توتنهام , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لاعب كره , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لاول مره , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لبحث ازم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لحر طالب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لحل ازم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لسد نهض , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لقاح استرازين , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لقاح كور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لقاح مضاد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لكر قدم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لوقف اطلاق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ليب ثقه , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ليب يعل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: لير ترك , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مانشستر سيت , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مبعوث امير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: متاثر اصاب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: متحد قلق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مجلس امن , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مجلس شيوخ , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مجلس نواب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: محادث سلام , vector: [0 0 0 ... 0 0 0]\n",
            "Word: محكم امر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: محكم ريطان , vector: [0 0 0 ... 0 0 0]\n",
            "Word: محمد بن , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مد قدس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مذكر تفا , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مركز ترك , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مسجد اقص , vector: [0 0 0 ... 1 0 0]\n",
            "Word: مشروع تصريف , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مضاد لكور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مظاهر حاشد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مفاوض سد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مفوض امم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مقاوم سطين , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مقر كال , vector: [0 0 0 ... 0 0 0]\n",
            "Word: مليار حجم , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ممل متحد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: منتد سان , vector: [0 0 0 ... 0 0 0]\n",
            "Word: منتد قطر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: منظم صحه , vector: [0 0 0 ... 0 0 0]\n",
            "Word: موج جديد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: موعد انتخاب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ميا يتظاهر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ميانمار جيش , vector: [0 0 0 ... 0 0 0]\n",
            "Word: نار اسراييل , vector: [0 0 0 ... 0 0 0]\n",
            "Word: نصر قدس , vector: [0 0 0 ... 0 0 0]\n",
            "Word: نصف نها , vector: [0 0 0 ... 0 0 0]\n",
            "Word: نقد دول , vector: [0 0 0 ... 0 0 0]\n",
            "Word: نها دور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: نواب ليب , vector: [0 0 0 ... 0 0 0]\n",
            "Word: نوو اير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: هجوم حوث , vector: [0 0 0 ... 0 0 0]\n",
            "Word: واشنط تعرض , vector: [0 0 0 ... 0 0 0]\n",
            "Word: وحد وطن , vector: [0 0 0 ... 0 0 0]\n",
            "Word: وروس دورتموند , vector: [0 0 0 ... 0 0 0]\n",
            "Word: وفد امير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: وقف احتجاج , vector: [0 0 0 ... 0 0 0]\n",
            "Word: وقف اطلاق , vector: [0 0 0 ... 0 0 0]\n",
            "Word: وقف عدوا , vector: [0 0 0 ... 0 0 0]\n",
            "Word: وقف قتال , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ول عهد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ولا متحد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: يبحث تعاو , vector: [0 0 0 ... 0 0 0]\n",
            "Word: يبحث نظير , vector: [0 0 0 ... 0 0 0]\n",
            "Word: يروس كور , vector: [0 0 0 ... 0 0 0]\n",
            "Word: يقر خطه , vector: [0 0 0 ... 0 0 0]\n",
            "Word: ينفرد صدار , vector: [0 0 0 ... 0 0 0]\n",
            "Word: يوقع مذكر , vector: [0 0 0 ... 0 0 0]\n",
            "Word: يوم احد , vector: [0 0 0 ... 0 0 0]\n",
            "Word: يويف يقرر , vector: [0 0 0 ... 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJx9T2Elb7tA"
      },
      "source": [
        "### **FastText**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fasttext"
      ],
      "metadata": {
        "id": "56T5S_VHbFHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e7b16a-10a6-4008-b3e9-b97b90d44c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4227138 sha256=2a03d415b433c1bc7ad6c776c88b2a1934383501470ed29a35064bc0db250b01\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFEXvk_Pcr7V",
        "outputId": "a6a3ccc1-68b8-42eb-d8fa-5542b88c90d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-22 17:32:01--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.96, 3.163.189.108, 3.163.189.51, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4500982519 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.ar.300.bin.gz’\n",
            "\n",
            "cc.ar.300.bin.gz    100%[===================>]   4.19G   112MB/s    in 46s     \n",
            "\n",
            "2024-05-22 17:32:47 (93.7 MB/s) - ‘cc.ar.300.bin.gz’ saved [4500982519/4500982519]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.bin.gz\"\n",
        "input_gz_file = '/content/cc.ar.300.bin.gz'\n",
        "output_bin_file = 'cc.ar.300.bin'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QVVpSQLb-ld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac7301e4-6f10-48b0-b74d-f8d2cdf8fe6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decompression successful: /content/cc.ar.300.bin.gz -> cc.ar.300.bin\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "\n",
        "def decompress_gz_to_bin(gz_file_path, bin_file_path):\n",
        "    try:\n",
        "        # Open the .gz file for reading\n",
        "        with gzip.open(gz_file_path, 'rb') as gz_file:\n",
        "            # Open or create the .bin file for writing\n",
        "            with open(bin_file_path, 'wb') as bin_file:\n",
        "                # Read chunks of data from the .gz file and write to the .bin file\n",
        "                while True:\n",
        "                    data = gz_file.read(1024)  # Read 1KB at a time\n",
        "                    if not data:\n",
        "                        break  # End of file\n",
        "                    bin_file.write(data)\n",
        "        print(f\"Decompression successful: {gz_file_path} -> {bin_file_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found: {gz_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "decompress_gz_to_bin(input_gz_file, output_bin_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcWIxu_deJps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838b586c-8c6f-46a8-acf8-a9d70496eda4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "\n",
        "ft = fasttext.load_model(output_bin_file)#('cc.ar.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OOV_tokens = []\n",
        "train_tokens = []\n",
        "test_tokens = []\n",
        "test_ft_embeddings = []\n",
        "\n",
        "def get_doc1_vec(sent, model, data):\n",
        "  tokens = sent.split()\n",
        "  ft_embeddings = []\n",
        "  for word in tokens:\n",
        "    try:\n",
        "      if news_train == 'train':\n",
        "        ft_embeddings.append(model.get_word_vector(word))\n",
        "        train_tokens.append(word)\n",
        "      else:\n",
        "        ft_embeddings.append(model.get_word_vector(word))\n",
        "        test_tokens.append(word)\n",
        "    except:\n",
        "      #print(word, 'does not exist in the model.')\n",
        "      OOV_tokens.append(word) #if found any -> go back to pre-processing the data\n",
        "      continue\n",
        "  if len(ft_embeddings) == 0:\n",
        "    return None\n",
        "  return sum(ft_embeddings)/len(ft_embeddings)"
      ],
      "metadata": {
        "id": "YCYYAeRLP2mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_ft_embeddings = X_train['processed_text'].apply(lambda sent: get_doc1_vec(sent, ft,'train'))\n",
        "X_test_ft_embeddings = X_test['processed_text'].apply(lambda sent: get_doc1_vec(sent, ft,'test'))"
      ],
      "metadata": {
        "id": "LE2ZrR4GcdSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_train_ft_embeddings_list = []\n",
        "for embedding in X_train_ft_embeddings:\n",
        "    if embedding is not None:\n",
        "        X_train_ft_embeddings_list.append(embedding)\n",
        "    else:\n",
        "        # Handle cases where the embedding is None\n",
        "        X_train_ft_embeddings_list.append(np.zeros_like(X_train_ft_embeddings))\n",
        "\n",
        "X_test_ft_embeddings_list = []\n",
        "for embedding in X_test_ft_embeddings:\n",
        "    if embedding is not None:\n",
        "        X_test_ft_embeddings_list.append(embedding)\n",
        "    else:\n",
        "        # Handle cases where the embedding is None\n",
        "        X_test_ft_embeddings_list.append(np.zeros_like(X_test_ft_embeddings))\n"
      ],
      "metadata": {
        "id": "sma_hTqFQcA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJAooC6La3IL"
      },
      "source": [
        "### **Bert**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO6SbFB0Uyz4",
        "outputId": "3b966556-2da3-4f6a-a7d2-580612710b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fszSrf9Fa249"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from nltk.tokenize import word_tokenize\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "# Specify the pre-trained model name\n",
        "model_name = \"aubmindlab/bert-base-arabert\"\n",
        "# Load pre-trained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "poZUrZLUa7ao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee38755-fc14-4b65-b417-8b0ec549cdab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_test['processed_text']"
      ],
      "metadata": {
        "id": "QTWn77-7dK9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessed_documents"
      ],
      "metadata": {
        "id": "jpYVdF8Yv8bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-luY92N0Ns-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83b42d2-adaa-422e-80a3-61973e0f79bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4250, 768])\n",
            "tensor([[-0.1490,  1.1868,  0.2667,  ...,  0.2583,  0.2940,  0.0725],\n",
            "        [-0.2271,  0.6840, -0.1094,  ..., -0.1598,  0.3695,  0.3029],\n",
            "        [-0.3242,  1.3685,  0.4638,  ...,  0.5177,  0.2432,  0.7376],\n",
            "        ...,\n",
            "        [-0.1692,  0.4645,  0.1335,  ..., -0.3017,  0.5016,  0.3602],\n",
            "        [-0.1568,  0.5496,  0.0083,  ..., -0.2557,  0.3265,  0.4287],\n",
            "        [-0.3076,  1.1313,  0.4750,  ...,  0.4929,  0.2663,  0.1684]])\n"
          ]
        }
      ],
      "source": [
        "token_ids_list =[]\n",
        "for sentence in X_train['processed_text']:\n",
        "  tokens = tokenizer.tokenize(sentence)\n",
        "  #print(tokens)\n",
        "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  #print(token_ids)\n",
        "  token_ids_list.append(token_ids)\n",
        "#print(token_ids_list)\n",
        "#len(token_ids_list)\n",
        "\n",
        "# Find the maximum length of tokenized documents\n",
        "max_length = max(len(token_ids) for token_ids in token_ids_list)\n",
        "\n",
        "# Pad the sequences\n",
        "padded_token_ids_list = [token_ids + [tokenizer.pad_token_id] * (max_length - len(token_ids)) for token_ids in token_ids_list]\n",
        "#print(padded_token_ids_list)\n",
        "#print(max_length)\n",
        "#len(padded_token_ids_list[1])\n",
        "\n",
        "token_ids_tensor = torch.tensor(padded_token_ids_list)\n",
        "#len(token_ids_tensor)\n",
        "\n",
        "# Pass token IDs through the model to get embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = model(token_ids_tensor)\n",
        "# Extract the embeddings\n",
        "embeddings_bert_X_train = outputs.last_hidden_state\n",
        "mean_embeddings_bert_X_train = torch.mean(embeddings_bert_X_train, dim=1)\n",
        "\n",
        "# Print the shape of the embeddings\n",
        "print(mean_embeddings_bert_X_train.shape)  # Output: torch.Size([1, num_tokens, hidden_size])\n",
        "print(mean_embeddings_bert_X_train)\n",
        "#i need to do the mean for each sentence (tokens) from lab 6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids_list =[]\n",
        "for sentence in X_test['processed_text']:\n",
        "  tokens = tokenizer.tokenize(sentence)\n",
        "  #print(tokens)\n",
        "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  #print(token_ids)\n",
        "  token_ids_list.append(token_ids)\n",
        "#print(token_ids_list)\n",
        "#len(token_ids_list)\n",
        "\n",
        "# Find the maximum length of tokenized documents\n",
        "max_length = max(len(token_ids) for token_ids in token_ids_list)\n",
        "\n",
        "# Pad the sequences\n",
        "padded_token_ids_list = [token_ids + [tokenizer.pad_token_id] * (max_length - len(token_ids)) for token_ids in token_ids_list]\n",
        "#print(padded_token_ids_list)\n",
        "#print(max_length)\n",
        "#len(padded_token_ids_list[1])\n",
        "\n",
        "token_ids_tensor = torch.tensor(padded_token_ids_list)\n",
        "#len(token_ids_tensor)\n",
        "\n",
        "# Pass token IDs through the model to get embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = model(token_ids_tensor)\n",
        "# Extract the embeddings\n",
        "embeddings_bert_X_test = outputs.last_hidden_state\n"
      ],
      "metadata": {
        "id": "C3sDD7CpfaWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_embeddings_bert_X_test = torch.mean(embeddings_bert_X_test, dim=1)\n",
        "\n",
        "# Print the shape of the embeddings\n",
        "print(mean_embeddings_bert_X_test.shape)  # Output: torch.Size([1, num_tokens, hidden_size])\n",
        "print(mean_embeddings_bert_X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvrMGMd5Oqg3",
        "outputId": "cdd5a858-0bfa-4a52-d92d-d18ac1610c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([750, 768])\n",
            "tensor([[ 0.0963,  0.4743,  0.0387,  ..., -0.2549,  0.4874,  0.1438],\n",
            "        [ 0.0346,  0.7638,  0.5607,  ..., -0.4772,  0.5471,  0.3590],\n",
            "        [-0.3641,  1.1202,  0.5697,  ...,  0.3550,  0.4005,  0.2886],\n",
            "        ...,\n",
            "        [-0.4267,  0.4340,  0.3929,  ...,  0.0027,  0.0734,  0.0695],\n",
            "        [-0.1716,  0.3511, -0.1088,  ..., -0.3545,  0.2532,  0.2152],\n",
            "        [-0.6457,  1.0996,  0.3639,  ...,  0.4253,  0.2711,  0.5477]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Models**"
      ],
      "metadata": {
        "id": "BsNsZ8dQg5q5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM**"
      ],
      "metadata": {
        "id": "Gor3-2Eig9zP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LSTM TF-IDF**"
      ],
      "metadata": {
        "id": "Mht-OgeShJUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LSTM Bag-Of-Words**"
      ],
      "metadata": {
        "id": "w5AcsDlnloCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LSTM FastText**"
      ],
      "metadata": {
        "id": "bNnDpW70mCo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LSTM Bert**"
      ],
      "metadata": {
        "id": "fn7UGYNPmNeC"
      }
    }
  ]
}